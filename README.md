# Predicting-House-Prices-Using-Linear-Regression-

## Project Overview

This project demonstrates how to predict house prices using Linear Regression, one of the most fundamental algorithms in machine learning. The notebook walks through data preprocessing, exploratory data analysis (EDA), model training, evaluation, and predictions.

The goal is to provide a simple yet practical approach to understanding how regression can be applied in real-world scenarios such as real estate price prediction.

## Repository Contents

Predicting House Prices Using Linear Regression.ipynb â€” Main Jupyter Notebook containing code, visualizations, and explanations.

USA Housing  â€” Dataset used for training and testing.

README.md â€” Project documentation.

## Requirements

Make sure you have the following installed before running the notebook:

python 3.8+
jupyter notebook
numpy
pandas
matplotlib
seaborn
scikit-learn


Install dependencies with:

pip install -r requirements.txt

## How to Run

Clone the repository:

git clone https://github.com/Sahil9175/Predicting-House-Prices-Using-Linear-Regression

Launch Jupyter Notebook:

Open Predicting House Prices Using Linear Regression.ipynb and run the cells step by step.

## Workflow

Import Libraries & Dataset
Load necessary Python libraries and the dataset.

Exploratory Data Analysis (EDA)

Understand data distribution

Handle missing values

Visualize relationships between features and price

Data Preprocessing

Feature selection & scaling

Train-test split

Model Training

Fit a Linear Regression model

Interpret coefficients

Model Evaluation

Evaluate using RÂ², MAE, MSE, RMSE

Visualize predicted vs actual values

Predictions

Use the trained model to predict house prices for unseen data.

## Results

Demonstrates how Linear Regression can capture trends in housing prices.

Provides insights into which features contribute most strongly to house prices.

Serves as a baseline model for more advanced algorithms (e.g., Ridge, Lasso, Random Forests, XGBoost).

## Future Improvements

Try advanced regression techniques (Ridge, Lasso, ElasticNet).

Feature engineering (interaction terms, polynomial features).

Compare performance with non-linear models (Decision Trees, Random Forests, Gradient Boosting).

Deploy the model as a simple web app.

ðŸ‘¤ Author

Sahil Palshetkar

LinkedIn -www.linkedin.com/in/sahil-palshetkar-473744280
